{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cde77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/scikit-learn-contrib/scikit-learn-extra/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def MSE(x, y):\n",
    "    d = x-y\n",
    "    dd = d*d\n",
    "    #print(x, y, x.shape, y.shape)\n",
    "    #return math.sqrt(np.sum(dd)/len(dd))\n",
    "    return np.sum(dd)/len(dd)\n",
    "\n",
    "def lagrangian(x, y):\n",
    "    return math.abs(x - y)\n",
    "\n",
    "X = np.asarray([[1, 2], [1, 4], [1, 0],\n",
    "                [4, 2], [4, 4], [4, 0]])\n",
    "\n",
    "#kmedoids = KMedoids(n_clusters=2, random_state=0, metric=MSE).fit(X)\n",
    "kmedoids = KMedoids(n_clusters=2, random_state=0).fit(X)\n",
    "print(\"labels =\", kmedoids.labels_)\n",
    "\n",
    "kmedoids.predict([[0,0], [4,4]])\n",
    "\n",
    "print(\"centers =\", kmedoids.cluster_centers_)\n",
    "\n",
    "print(\"inertia =\", kmedoids.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = np.asarray([[1, 2], [1, 4], [1, 0],\n",
    "                [4, 2], [4, 4], [4, 0]])\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "#kmeans.fit(X)\n",
    "Y = kmeans.fit_transform(X)\n",
    "print(\"labels =\", kmeans.labels_)\n",
    "\n",
    "kmeans.predict([[0,0], [4,4]])\n",
    "\n",
    "print(\"centers =\", kmeans.cluster_centers_)\n",
    "\n",
    "print(\"inertia =\", kmeans.inertia_)\n",
    "\n",
    "print(X, Y)\n",
    "#kmeans.get_feature_names_out()\n",
    "#kmeans.get_params()\n",
    "kmeans.score(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Robert Layton <robertlayton@gmail.com>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "\n",
    "n_colors = 64\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) / 255\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h, d = original_shape = tuple(china.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(china, (w * h, d))\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000)\n",
    "kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "labels_random = pairwise_distances_argmin(codebook_random, image_array, axis=0)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)\n",
    "\n",
    "\n",
    "# Display all results, alongside original image\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original image (96,615 colors)\")\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, K-Means)\")\n",
    "plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n",
    "\n",
    "plt.figure(3)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, Random)\")\n",
    "plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Robert Layton <robertlayton@gmail.com>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "\n",
    "n_colors = 64\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) / 255\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h, d = original_shape = tuple(china.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(china, (w * h, d))\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000)\n",
    "kmeans = KMedoids(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "labels_random = pairwise_distances_argmin(codebook_random, image_array, axis=0)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)\n",
    "\n",
    "\n",
    "# Display all results, alongside original image\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original image (96,615 colors)\")\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, K-Medoids)\")\n",
    "plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n",
    "\n",
    "plt.figure(3)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, Random)\")\n",
    "plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "\n",
    "n_colors = 8\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) #/ 255\n",
    "print(china.shape)\n",
    "china = (( china[...,0] + china[...,1] + china[...,0] ) / 3).astype(np.uint8)\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h = original_shape = tuple(china.shape)\n",
    "image_array = np.reshape(china, w * h)\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000).reshape(-1, 1)\n",
    "kmeans = KMedoids(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array.reshape(-1, 1))\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "print(np.unique(labels))\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "#labels_random = pairwise_distances_argmin(codebook_random, image_array.reshape(-1, 1), axis=0)\n",
    "#print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)\n",
    "\n",
    "\n",
    "# Display all results, alongside original image\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original image (96,615 colors)\")\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, K-Medoids)\")\n",
    "y = recreate_image(kmeans.cluster_centers_, labels, w, h)\n",
    "print(np.unique(y))\n",
    "plt.imshow(y)\n",
    "\n",
    "#plt.figure(3)\n",
    "#plt.clf()\n",
    "#plt.axis(\"off\")\n",
    "#plt.title(f\"Quantized image ({n_colors} colors, Random)\")\n",
    "#plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77201e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "\n",
    "print(f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\")\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(\n",
    "            data,\n",
    "            estimator[-1].labels_,\n",
    "            metric=\"euclidean\",\n",
    "            sample_size=300,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\n",
    "        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
    "    )\n",
    "    print(formatter_result.format(*results))\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(82 * \"_\")\n",
    "print(\"init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\")\n",
    "\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
    "\n",
    "kmeans = KMeans(init=\"random\", n_clusters=n_digits, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
    "\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "kmeans = KMeans(init=pca.components_, n_clusters=n_digits, n_init=1)\n",
    "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
    "\n",
    "print(82 * \"_\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centroids are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "\n",
    "print(f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\")\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(\n",
    "            data,\n",
    "            estimator[-1].labels_,\n",
    "            metric=\"euclidean\",\n",
    "            sample_size=300,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\n",
    "        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
    "    )\n",
    "    print(formatter_result.format(*results))\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids as KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(82 * \"_\")\n",
    "print(\"init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\")\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_digits, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_digits, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
    "\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "kmeans = KMeans(n_clusters=n_digits)\n",
    "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
    "\n",
    "print(82 * \"_\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(n_clusters=n_digits)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-medoids clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centers are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d763a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "\n",
    "print(f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\")\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(\n",
    "            data,\n",
    "            estimator[-1].labels_,\n",
    "            metric=\"euclidean\",\n",
    "            sample_size=300,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\n",
    "        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
    "    )\n",
    "    print(formatter_result.format(*results))\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids as KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def lagrangian(x, y):\n",
    "    d = x-y\n",
    "    dd = d*d\n",
    "    #print(x, y, x.shape, y.shape)\n",
    "    #return math.sqrt(np.sum(dd)/len(dd))\n",
    "    return np.sum(dd)/len(dd)\n",
    "    #return abs(x - y)\n",
    "\n",
    "print(82 * \"_\")\n",
    "print(\"init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\")\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_digits, random_state=0, metric=lagrangian)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_digits, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
    "\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "kmeans = KMeans(n_clusters=n_digits)\n",
    "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
    "\n",
    "print(82 * \"_\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(n_clusters=n_digits, metric=lagrangian)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-medoids clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centers are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids as K_cluster\n",
    "#from sklearn.cluster import KMeans as K_cluster\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def MSE(x, y):\n",
    "    d = x-y\n",
    "    dd = d*d\n",
    "    #print(x, y, x.shape, y.shape)\n",
    "    #return math.sqrt(np.sum(dd)/len(dd))\n",
    "    return np.sum(dd)/len(dd)\n",
    "\n",
    "_lambda = 1.0\n",
    "\n",
    "def lagrangian(x, y):\n",
    "    distortion = abs(x - y)\n",
    "    rate = math.log(distortion + 1)\n",
    "    return rate + _lambda*distortion\n",
    "\n",
    "X = np.asarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0]).reshape(-1, 1)\n",
    "\n",
    "clusterer = K_cluster(n_clusters=2, random_state=0, metric=lagrangian).fit(X)\n",
    "#clusterer = K_cluster(n_clusters=2, random_state=0).fit(X)\n",
    "print(\"labels =\", clusterer.labels_)\n",
    "print(\"centers =\", clusterer.cluster_centers_)\n",
    "print(\"inertia =\", clusterer.inertia_)\n",
    "\n",
    "clusterer.predict(np.asarray([1, 4]).reshape(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50170d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "def entropy(sequence_of_symbols):\n",
    "    assert sequence_of_symbols.ndim == 1\n",
    "    value, counts = np.unique(sequence_of_symbols, return_counts = True)\n",
    "    probs = counts / len(sequence_of_symbols)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    _entropy = 0.\n",
    "    for i in probs:\n",
    "        _entropy -= i * math.log(i, 2)\n",
    "\n",
    "    return _entropy\n",
    "\n",
    "_lambda = 0\n",
    "\n",
    "def lagrangian(x, y):\n",
    "    distortion = abs(x - y)\n",
    "    return distortion\n",
    "    #rate = math.log(np.sum(abs(x-y)) + 1)\n",
    "    #return distortion + _lambda * rate\n",
    "\n",
    "def lagrangian(x, y):\n",
    "    d = x-y\n",
    "    dd = d*d\n",
    "    #print(x, y, x.shape, y.shape)\n",
    "    #return math.sqrt(np.sum(dd)/len(dd))\n",
    "    distortion = math.sqrt(np.sum(dd)/len(dd)) # dd is an array of 3 components (RGB)\n",
    "    rate = math.log(np.sum(abs(d)) + 1)\n",
    "    #print(np.sum(abs(x-y)), rate, x.shape, y.shape)\n",
    "    return distortion + _lambda * rate\n",
    "\n",
    "n_colors = 8\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) / 255\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h, d = original_shape = tuple(china.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(china, (w * h, d))\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000)\n",
    "kmeans = KMedoids(n_clusters=n_colors, random_state=0, metric=lagrangian).fit(image_array_sample)\n",
    "#kmeans = KMedoids(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "labels_random = pairwise_distances_argmin(codebook_random, image_array, axis=0)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")\n",
    "\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)\n",
    "\n",
    "\n",
    "# Display all results, alongside original image\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original image (96,615 colors)\")\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, K-Medoids)\")\n",
    "plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n",
    "\n",
    "plt.figure(3)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, Random)\")\n",
    "plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats import entropy\n",
    "d = china - recreate_image(kmeans.cluster_centers_, labels, w, h)\n",
    "dd = d*d\n",
    "print(math.sqrt(np.sum(dd)/len(dd)), entropy(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e262601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
